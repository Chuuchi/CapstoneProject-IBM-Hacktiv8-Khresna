# CapstoneProject-IBM-Hacktiv8-Khresna

## Title Project
Toxic Comments in Wikipedia Classification and Analysis using Google Colab and IBM Granite


## Project Overview
This project uses the Jigsaw Toxic Comment Classification dataset to classify user comments on wikipedia as toxic or not and analyze them. The focus is on identifying and analyzing problematic comment patterns commonly found on online platforms such as wikipedia. With the classification of toxic and non-toxic comments, a platform can create features so that its users have the option to hide toxic comments.


## Raw Dataset Link
> Deep Learning For NLP: Zero To Transformers & BERT
> 
https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert/notebook


## Insight and Finding
- Most of the comments were not in the toxic category (77.9%), indicating a predominance of neutral or positive comments.
- It turns out that online platforms like wikipedia contain quite a few negative comments.
- Toxic and Obscene are the most frequently occurring toxic categories.
- The bar chart visualization shows the distribution of inequality between toxic categories, helping to identify the types of comments that need the most scrutiny.


## AI Support Explanation
The IBM Granite model is used as a support in understanding the sentiment and context of user comments. This model is capable of classification based on understanding complex natural language context. Granite can recognize negative comments even without explicit abusive words. This makes it an excellent tool for handling toxic comment data that is often ambiguous or implicit.

